{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv8i1cjiXNnSeEYlM+On4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajidminhas/Crew-AI/blob/main/RAG-PINECONE/Rag_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "toy_MC5S47nC"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(\n",
        "    api_key=userdata.get('GOOGLE_API_KEY')\n",
        ")\n"
      ],
      "metadata": {
        "id": "-0lVLOGq5qRU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g9cTOdoj6jvG",
        "outputId": "fd2445c0-1eea-4bef-cf08-5f69a98f86af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-27b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 27B',\n",
              "       description='',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp-03-07',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental 03-07',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0 002 model',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model = 'models/text-embedding-004',\n",
        "    content = 'what is agentic ai',\n",
        "    task_type= 'retrieval_document', # Changed 'embedding' to 'retrieval_document'\n",
        "    title= 'agentic ai'\n",
        ")\n",
        "\n",
        "result['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "eEr36POANBww",
        "outputId": "3b7c05fd-8b8a-4426-b34d-d745324eac90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012421869,\n",
              " 0.03269651,\n",
              " 0.015868923,\n",
              " -0.0129535915,\n",
              " -0.056787577,\n",
              " 0.039955895,\n",
              " 0.017332971,\n",
              " 0.033023883,\n",
              " 0.059590008,\n",
              " 0.022964427,\n",
              " -0.017804712,\n",
              " -0.004420217,\n",
              " 0.03635456,\n",
              " -0.008579132,\n",
              " 0.008323925,\n",
              " -0.05314491,\n",
              " 0.057409238,\n",
              " 0.014160487,\n",
              " -0.07729618,\n",
              " 0.013833791,\n",
              " 0.025539763,\n",
              " 0.012306152,\n",
              " -0.0330855,\n",
              " -0.07165854,\n",
              " -0.027296262,\n",
              " -0.043799512,\n",
              " 0.046907734,\n",
              " 0.02962763,\n",
              " -0.015693054,\n",
              " 0.030743042,\n",
              " 0.06756377,\n",
              " 0.03323955,\n",
              " 0.021388065,\n",
              " -0.060810074,\n",
              " 0.01635045,\n",
              " -0.021960787,\n",
              " -0.032452334,\n",
              " 0.035286214,\n",
              " 0.041525792,\n",
              " -0.06033893,\n",
              " -0.06131643,\n",
              " 0.030265605,\n",
              " -0.044580154,\n",
              " 0.020428983,\n",
              " -0.052024435,\n",
              " -0.0071186367,\n",
              " -0.008617047,\n",
              " 0.067096114,\n",
              " -0.05236938,\n",
              " 0.024789827,\n",
              " -0.017271286,\n",
              " -0.026936995,\n",
              " -0.041028906,\n",
              " 0.0051763514,\n",
              " -0.03830445,\n",
              " -0.010935375,\n",
              " -0.012728411,\n",
              " -0.0032018067,\n",
              " 0.021408843,\n",
              " -0.016748177,\n",
              " -0.082120344,\n",
              " 0.011491257,\n",
              " 0.0003596019,\n",
              " -0.020418568,\n",
              " 0.032060347,\n",
              " -0.0127804,\n",
              " -0.021024542,\n",
              " 0.03420162,\n",
              " -0.030051986,\n",
              " -0.0029032324,\n",
              " -0.01859204,\n",
              " -0.053091936,\n",
              " -0.019476162,\n",
              " 0.0022184344,\n",
              " -0.004894508,\n",
              " 0.005476633,\n",
              " -0.021586401,\n",
              " -0.047632918,\n",
              " 0.003522525,\n",
              " 0.04669154,\n",
              " 0.013391363,\n",
              " 0.015683772,\n",
              " 0.05040786,\n",
              " 0.07207488,\n",
              " -0.014103537,\n",
              " -0.12248648,\n",
              " 0.022052063,\n",
              " -0.064876616,\n",
              " -0.077302024,\n",
              " -0.0037087626,\n",
              " 0.007857554,\n",
              " -0.0047561848,\n",
              " 0.021423556,\n",
              " -0.007765579,\n",
              " 0.04208432,\n",
              " -0.0039602765,\n",
              " -0.013220349,\n",
              " -0.025633974,\n",
              " 0.075531326,\n",
              " -0.016534787,\n",
              " -0.007271466,\n",
              " 0.033936992,\n",
              " -0.054463986,\n",
              " -0.02482379,\n",
              " 0.09437774,\n",
              " 0.09717999,\n",
              " 0.0037221513,\n",
              " 0.038877062,\n",
              " -0.042074062,\n",
              " 0.054279994,\n",
              " 0.0066365483,\n",
              " -0.021003826,\n",
              " 0.0165736,\n",
              " -0.06858521,\n",
              " -0.012561012,\n",
              " 0.0048964885,\n",
              " -0.06381432,\n",
              " 0.024369566,\n",
              " -0.012531106,\n",
              " -0.041854274,\n",
              " -0.018767545,\n",
              " 0.051944192,\n",
              " -0.0008424376,\n",
              " 0.033686537,\n",
              " 0.06894906,\n",
              " -0.007669488,\n",
              " 0.004492243,\n",
              " -0.038172904,\n",
              " -0.06742074,\n",
              " -0.019328304,\n",
              " 0.067840956,\n",
              " -0.13458075,\n",
              " 0.01887801,\n",
              " 0.04686907,\n",
              " -0.031244608,\n",
              " -0.0013262104,\n",
              " 0.07795274,\n",
              " -0.037209257,\n",
              " 0.016513059,\n",
              " -0.01060479,\n",
              " 0.041237153,\n",
              " 0.013465899,\n",
              " -0.03392451,\n",
              " 0.029871153,\n",
              " 0.056672417,\n",
              " 0.010980522,\n",
              " -0.04387345,\n",
              " -0.011924351,\n",
              " -0.03177317,\n",
              " -0.05882412,\n",
              " -0.017887436,\n",
              " 0.016470645,\n",
              " 0.021004401,\n",
              " 0.024784517,\n",
              " -0.023356512,\n",
              " 0.019817004,\n",
              " -0.0037145077,\n",
              " -0.027565252,\n",
              " 0.071168944,\n",
              " -0.058483593,\n",
              " -0.006036318,\n",
              " -0.028740114,\n",
              " 0.0413343,\n",
              " -0.02024717,\n",
              " -0.019397642,\n",
              " -0.007285869,\n",
              " 0.014240452,\n",
              " -0.030312136,\n",
              " -0.012134454,\n",
              " 0.0067963363,\n",
              " 0.027740793,\n",
              " 0.066951334,\n",
              " 0.027485447,\n",
              " -0.07985805,\n",
              " 0.020511659,\n",
              " -7.4966665e-05,\n",
              " -0.020239064,\n",
              " -0.05040003,\n",
              " -0.024040658,\n",
              " -0.03388939,\n",
              " 0.13755076,\n",
              " 0.015324563,\n",
              " 0.0025654102,\n",
              " -0.10679595,\n",
              " 0.044875998,\n",
              " 0.050203674,\n",
              " -0.04777739,\n",
              " 0.004329015,\n",
              " 0.037569635,\n",
              " 0.028098565,\n",
              " -0.015955029,\n",
              " -0.05007525,\n",
              " -0.0075096376,\n",
              " 0.013057962,\n",
              " 0.024470933,\n",
              " 0.0047137304,\n",
              " -0.03131992,\n",
              " -0.034228172,\n",
              " 0.022399714,\n",
              " -0.03547637,\n",
              " 0.032174695,\n",
              " 0.026599927,\n",
              " 0.033498056,\n",
              " -0.033682983,\n",
              " -0.02812358,\n",
              " 0.013670747,\n",
              " 0.0035341794,\n",
              " -0.06628702,\n",
              " 0.04954597,\n",
              " 0.025852706,\n",
              " -0.017582376,\n",
              " -0.026462412,\n",
              " -0.013976084,\n",
              " -0.039574217,\n",
              " -0.034039784,\n",
              " 0.012257884,\n",
              " 0.034115322,\n",
              " -0.022869145,\n",
              " 0.007215108,\n",
              " -0.06539385,\n",
              " -0.029094664,\n",
              " -0.036602627,\n",
              " -0.0010901308,\n",
              " -0.012583318,\n",
              " 0.00068149116,\n",
              " 0.049243942,\n",
              " -0.028152253,\n",
              " -0.06648121,\n",
              " 0.020441202,\n",
              " -0.024801347,\n",
              " -0.0045261974,\n",
              " -0.019136958,\n",
              " -0.04799628,\n",
              " 0.011930987,\n",
              " -0.05586907,\n",
              " 0.038171835,\n",
              " 0.029543882,\n",
              " -0.0105363345,\n",
              " -0.02223885,\n",
              " 0.034373023,\n",
              " -0.012052039,\n",
              " 0.03377153,\n",
              " 0.021214014,\n",
              " -0.07730231,\n",
              " 0.011652865,\n",
              " 0.05799895,\n",
              " -0.04215354,\n",
              " 0.057080038,\n",
              " 0.018750738,\n",
              " -0.056793038,\n",
              " -0.015124467,\n",
              " -0.022274083,\n",
              " -0.02284489,\n",
              " -0.008914199,\n",
              " -0.06476595,\n",
              " -0.08258854,\n",
              " 0.022904022,\n",
              " 0.013953551,\n",
              " -0.002342401,\n",
              " -0.009485985,\n",
              " -0.008517602,\n",
              " -0.010908511,\n",
              " 0.019549966,\n",
              " -0.07949673,\n",
              " 0.018000934,\n",
              " -0.09304846,\n",
              " -0.034160107,\n",
              " 0.0044517503,\n",
              " 0.028250966,\n",
              " -0.021319598,\n",
              " 0.014041361,\n",
              " -0.006789925,\n",
              " -0.023140097,\n",
              " -0.031151513,\n",
              " -0.008482613,\n",
              " 0.058677837,\n",
              " -0.032608904,\n",
              " 0.061297726,\n",
              " -0.041096773,\n",
              " 0.020076288,\n",
              " 0.048192102,\n",
              " 0.031402256,\n",
              " 0.00074953435,\n",
              " -0.024066608,\n",
              " -0.0069280057,\n",
              " -0.040303126,\n",
              " 0.015623542,\n",
              " 0.0025354405,\n",
              " -0.011768568,\n",
              " -0.03309595,\n",
              " 0.050016504,\n",
              " 0.022173777,\n",
              " -0.006554039,\n",
              " -0.011961626,\n",
              " 0.011376887,\n",
              " 0.017197173,\n",
              " 0.066009216,\n",
              " 0.018777156,\n",
              " 0.026251428,\n",
              " 0.011601015,\n",
              " -0.01619434,\n",
              " 0.044240214,\n",
              " -0.029112937,\n",
              " 0.041344754,\n",
              " -0.016771583,\n",
              " 0.030182663,\n",
              " -0.0142814135,\n",
              " -0.028892716,\n",
              " -0.025726052,\n",
              " 0.017665045,\n",
              " 0.0077572567,\n",
              " -0.0019609702,\n",
              " 0.02987749,\n",
              " -0.087145485,\n",
              " -0.01587223,\n",
              " -0.020955458,\n",
              " -0.1034552,\n",
              " -0.010661011,\n",
              " -0.083001696,\n",
              " -0.013684911,\n",
              " 0.037108585,\n",
              " -0.01633755,\n",
              " -0.050059523,\n",
              " 0.02965148,\n",
              " 0.023042649,\n",
              " 0.021501852,\n",
              " 0.014228989,\n",
              " 0.059212998,\n",
              " 0.006975948,\n",
              " 0.0043009757,\n",
              " 0.052652813,\n",
              " 0.028505174,\n",
              " -0.049389366,\n",
              " -0.05592588,\n",
              " 0.008757692,\n",
              " 0.012305716,\n",
              " -0.02248329,\n",
              " 0.02591764,\n",
              " 0.03820679,\n",
              " 0.03147709,\n",
              " -0.00027714478,\n",
              " -0.0011169527,\n",
              " 0.03519323,\n",
              " 0.06759883,\n",
              " -0.031714227,\n",
              " 0.023659099,\n",
              " 0.046823304,\n",
              " 0.039356954,\n",
              " 0.03647196,\n",
              " -0.003379633,\n",
              " -0.021022823,\n",
              " 0.026107505,\n",
              " 0.029433804,\n",
              " 0.012525621,\n",
              " -0.013132027,\n",
              " -0.023150755,\n",
              " 0.041549757,\n",
              " -0.035991427,\n",
              " 0.005300614,\n",
              " -0.014823257,\n",
              " -0.03318746,\n",
              " 0.0013150721,\n",
              " 0.004695845,\n",
              " 0.011168576,\n",
              " -0.0013066359,\n",
              " -0.014059851,\n",
              " -0.0144058345,\n",
              " -0.0006556317,\n",
              " 0.030396143,\n",
              " -0.010123465,\n",
              " 0.0063974382,\n",
              " -0.02554013,\n",
              " 0.07067103,\n",
              " -0.034271516,\n",
              " 0.03492266,\n",
              " -0.05768454,\n",
              " 0.023516381,\n",
              " 0.07683771,\n",
              " 0.036773298,\n",
              " -0.0031505593,\n",
              " 0.035894495,\n",
              " -0.08201679,\n",
              " 0.016694015,\n",
              " 0.008786679,\n",
              " -0.02367066,\n",
              " 0.0674887,\n",
              " -0.03805552,\n",
              " -0.028019825,\n",
              " 0.037491795,\n",
              " 0.0013911619,\n",
              " -0.029314896,\n",
              " 0.0047742147,\n",
              " 0.03032953,\n",
              " 0.039859693,\n",
              " -0.00088101474,\n",
              " -0.0022112322,\n",
              " -0.008416298,\n",
              " 0.017348709,\n",
              " 0.014648135,\n",
              " 0.020157311,\n",
              " -0.022963885,\n",
              " 0.049486946,\n",
              " 0.077741995,\n",
              " -0.061878093,\n",
              " -0.03107868,\n",
              " 0.015996806,\n",
              " 0.060163077,\n",
              " 0.01863927,\n",
              " 0.0046441173,\n",
              " 0.008907246,\n",
              " -0.0040186974,\n",
              " -0.047834706,\n",
              " -0.025678778,\n",
              " -0.0011678133,\n",
              " -0.038945056,\n",
              " 0.012439676,\n",
              " 0.08257088,\n",
              " -0.014185524,\n",
              " 0.010263713,\n",
              " 0.067004144,\n",
              " 0.023673937,\n",
              " -0.015230395,\n",
              " 0.010173138,\n",
              " -0.035338968,\n",
              " -0.015414943,\n",
              " -0.049292825,\n",
              " -0.053245563,\n",
              " 0.031472757,\n",
              " 0.008131056,\n",
              " 0.039272785,\n",
              " -0.0075995303,\n",
              " -0.01254241,\n",
              " -0.04256544,\n",
              " 0.045236334,\n",
              " -0.00832941,\n",
              " 0.038588062,\n",
              " -0.017840268,\n",
              " 0.016850965,\n",
              " -0.049365,\n",
              " 0.019450992,\n",
              " -0.014652209,\n",
              " 0.03691467,\n",
              " 0.018072352,\n",
              " 0.033786137,\n",
              " -0.009166562,\n",
              " 0.016214577,\n",
              " 0.043790493,\n",
              " 0.06535752,\n",
              " 0.017429048,\n",
              " -0.03682196,\n",
              " 0.01856931,\n",
              " -0.01009446,\n",
              " 0.020845555,\n",
              " -0.06293032,\n",
              " -0.03520024,\n",
              " 0.017710987,\n",
              " 0.050239682,\n",
              " -0.026410151,\n",
              " 0.02300921,\n",
              " -0.010705519,\n",
              " 0.0026829573,\n",
              " -0.023088994,\n",
              " 0.014600727,\n",
              " 0.036334325,\n",
              " 0.0026958135,\n",
              " -0.02656986,\n",
              " 0.01602478,\n",
              " 0.021526009,\n",
              " -0.069603495,\n",
              " -0.0018928013,\n",
              " 0.039213404,\n",
              " -0.009542853,\n",
              " 0.03142349,\n",
              " -0.00022354489,\n",
              " -0.044873394,\n",
              " 0.0026879292,\n",
              " 0.06700403,\n",
              " 0.0040618363,\n",
              " 0.046095148,\n",
              " -0.017808907,\n",
              " 0.020044079,\n",
              " 0.01884816,\n",
              " 0.044566546,\n",
              " 0.04615645,\n",
              " 0.03361405,\n",
              " -0.06259725,\n",
              " -0.03326966,\n",
              " -0.014959313,\n",
              " 0.007012143,\n",
              " -0.013492252,\n",
              " -0.0026648226,\n",
              " 0.011328836,\n",
              " -0.030881498,\n",
              " -0.041407395,\n",
              " -0.021119813,\n",
              " 0.03903241,\n",
              " 0.031368308,\n",
              " -0.011939555,\n",
              " 0.073271714,\n",
              " 0.046694808,\n",
              " 0.03524324,\n",
              " 0.025747638,\n",
              " -0.0040647136,\n",
              " -0.013290272,\n",
              " 0.010246866,\n",
              " 0.011096114,\n",
              " 0.0059665088,\n",
              " -0.004939028,\n",
              " 0.0131425345,\n",
              " 0.037676524,\n",
              " 0.04110713,\n",
              " -0.02793533,\n",
              " 0.04307374,\n",
              " 0.034865964,\n",
              " 0.045921147,\n",
              " 0.02854321,\n",
              " -0.009616098,\n",
              " -0.0057204315,\n",
              " 0.016815102,\n",
              " 0.022778915,\n",
              " -0.045168743,\n",
              " -0.02600118,\n",
              " 0.022611827,\n",
              " -0.019541165,\n",
              " -0.0096514225,\n",
              " -0.045092735,\n",
              " -0.04220578,\n",
              " -0.0031145022,\n",
              " 0.012456278,\n",
              " -0.02370111,\n",
              " -0.021229912,\n",
              " 0.08305818,\n",
              " 0.04597001,\n",
              " 0.03435071,\n",
              " -0.004146979,\n",
              " 0.013689623,\n",
              " 0.0022822693,\n",
              " 0.011879946,\n",
              " 0.02377615,\n",
              " 0.020429455,\n",
              " -0.00015956617,\n",
              " -0.02812771,\n",
              " 0.04531406,\n",
              " -0.02702456,\n",
              " 0.031365845,\n",
              " -0.019729067,\n",
              " -0.0318057,\n",
              " 0.06901725,\n",
              " -0.0053359224,\n",
              " 0.06798267,\n",
              " 0.046352103,\n",
              " -0.034369413,\n",
              " 0.061669346,\n",
              " 0.041753463,\n",
              " 0.006999215,\n",
              " -0.0024084984,\n",
              " 0.043111872,\n",
              " -0.0055447654,\n",
              " -0.01083531,\n",
              " 0.010290186,\n",
              " -0.046989083,\n",
              " -0.045163758,\n",
              " 0.01596343,\n",
              " -0.017584402,\n",
              " 0.041815944,\n",
              " 0.01891068,\n",
              " -0.00088070566,\n",
              " -0.00041173017,\n",
              " -0.013943174,\n",
              " -0.01277673,\n",
              " -0.017109135,\n",
              " -0.0013265678,\n",
              " -0.03261542,\n",
              " 0.009077924,\n",
              " -0.06541988,\n",
              " -0.024453258,\n",
              " -0.007358545,\n",
              " 0.028050309,\n",
              " -0.014036544,\n",
              " -0.061281852,\n",
              " 0.020575121,\n",
              " -0.014395848,\n",
              " 0.009826827,\n",
              " -0.059530884,\n",
              " -0.021165714,\n",
              " 0.00021958249,\n",
              " -0.023079483,\n",
              " 0.010591956,\n",
              " 0.02107539,\n",
              " 0.046026766,\n",
              " -0.043587327,\n",
              " 0.048648626,\n",
              " 0.012608858,\n",
              " -0.04762885,\n",
              " -0.014725044,\n",
              " 0.033647884,\n",
              " -0.0982679,\n",
              " 0.057105176,\n",
              " 0.019008894,\n",
              " 0.024358928,\n",
              " 0.003004414,\n",
              " -0.024081796,\n",
              " -0.004165165,\n",
              " 0.012777554,\n",
              " -0.02412914,\n",
              " -0.022789849,\n",
              " -0.040142328,\n",
              " -0.0075779385,\n",
              " 0.021267721,\n",
              " 0.01629015,\n",
              " 0.049329907,\n",
              " 0.036044847,\n",
              " 0.009064024,\n",
              " -0.037802454,\n",
              " -0.064094245,\n",
              " -0.012417759,\n",
              " -0.029282466,\n",
              " 0.015491491,\n",
              " -0.040128093,\n",
              " -0.033650402,\n",
              " -0.03862311,\n",
              " 0.029301725,\n",
              " 0.023745505,\n",
              " 0.004999196,\n",
              " 0.004741174,\n",
              " -0.028350092,\n",
              " -0.013213542,\n",
              " -0.010013218,\n",
              " 0.024820188,\n",
              " 0.027014889,\n",
              " -0.0057186787,\n",
              " 0.03182377,\n",
              " 0.049567312,\n",
              " -0.067720495,\n",
              " 0.030027866,\n",
              " 0.040580645,\n",
              " 0.05801887,\n",
              " -0.008393579,\n",
              " 0.015615615,\n",
              " -0.041620914,\n",
              " 0.006023144,\n",
              " -0.03751639,\n",
              " 0.052764952,\n",
              " 0.009193506,\n",
              " -0.015873792,\n",
              " 0.03598206,\n",
              " -0.0058371993,\n",
              " -0.034550045,\n",
              " -0.018574111,\n",
              " -0.0017427468,\n",
              " -0.004260585,\n",
              " -0.016215146,\n",
              " -0.026369834,\n",
              " 0.010370191,\n",
              " -0.06273779,\n",
              " -0.050810933,\n",
              " -0.0138794435,\n",
              " -0.021775274,\n",
              " 0.033516284,\n",
              " -0.013908459,\n",
              " 0.011830656,\n",
              " -0.013391021,\n",
              " -0.0053720754,\n",
              " 0.015015382,\n",
              " -0.036753435,\n",
              " -0.008494295,\n",
              " -0.012473687,\n",
              " 0.008019333,\n",
              " 0.02522902,\n",
              " -0.025038395,\n",
              " -0.02204694,\n",
              " 0.006655469,\n",
              " -0.01183351,\n",
              " 0.042603012,\n",
              " 0.01806484,\n",
              " 0.027803851,\n",
              " 0.031712405,\n",
              " -0.01675687,\n",
              " -0.032368135,\n",
              " 0.025817163,\n",
              " 0.018598896,\n",
              " -0.094728105,\n",
              " -0.026164543,\n",
              " 0.005234993,\n",
              " -0.005770621,\n",
              " -0.026396325,\n",
              " 0.006041259,\n",
              " 0.022513816,\n",
              " -0.057360288,\n",
              " 0.04863436,\n",
              " -0.042472143,\n",
              " 0.00081177393,\n",
              " 0.007264401,\n",
              " -0.038170975,\n",
              " -0.0033686012,\n",
              " 0.019806722,\n",
              " -0.010525044,\n",
              " -0.0011514281,\n",
              " -0.035622273,\n",
              " -0.025570694,\n",
              " -0.0075140526,\n",
              " -0.03959501,\n",
              " -0.09431673,\n",
              " -0.0042859893,\n",
              " -0.02991375,\n",
              " 0.04920727,\n",
              " 0.057406627,\n",
              " -0.0011629222,\n",
              " -0.12018017,\n",
              " -0.0046193358,\n",
              " -0.05823395,\n",
              " 0.0650016,\n",
              " 0.038292713,\n",
              " 0.014958703,\n",
              " 0.007126694,\n",
              " -0.01855346,\n",
              " 0.051846407,\n",
              " 0.032054737,\n",
              " 0.004892608,\n",
              " 0.011879134,\n",
              " 0.012370398,\n",
              " -0.017533857,\n",
              " 0.033826794,\n",
              " 0.06250859,\n",
              " 0.017727481,\n",
              " -0.05513117,\n",
              " -0.048194908,\n",
              " 0.021371374,\n",
              " -0.0202496,\n",
              " 0.04627482,\n",
              " 0.021241026,\n",
              " -0.050775755,\n",
              " -0.021269966,\n",
              " 0.050550036,\n",
              " 0.011839046,\n",
              " -0.021409582,\n",
              " -0.040776804,\n",
              " 0.031184804,\n",
              " -0.089618534,\n",
              " 0.018755546,\n",
              " -0.004214076,\n",
              " -0.01226937,\n",
              " 0.0014927419,\n",
              " -0.015779821,\n",
              " 0.010131963,\n",
              " 0.0061065615,\n",
              " -0.021896115,\n",
              " -0.028271327,\n",
              " -0.016993394,\n",
              " -0.027000183,\n",
              " -0.03209057,\n",
              " 0.0400083,\n",
              " -0.0028806096,\n",
              " 0.046648998,\n",
              " -0.012094483,\n",
              " -0.013336228,\n",
              " -0.0140598,\n",
              " -0.017243866,\n",
              " 0.012125573,\n",
              " 0.054876424,\n",
              " -0.05118176,\n",
              " 0.095878825,\n",
              " -0.018203938,\n",
              " 0.06131257,\n",
              " -0.027011054,\n",
              " -0.062332887,\n",
              " 0.004577869,\n",
              " -0.008746573]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}